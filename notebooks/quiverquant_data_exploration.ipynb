{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "962fab21",
   "metadata": {},
   "source": [
    "# üî¨ QuiverQuant Data Exploration Notebook\n",
    "\n",
    "**Objectif:** Tester et explorer les donn√©es QuiverQuant petit √† petit pour comprendre les formats, la qualit√© et la structure.\n",
    "\n",
    "**Date:** 31 D√©cembre 2025  \n",
    "**Token:** bibep  \n",
    "\n",
    "---\n",
    "\n",
    "## üìã Plan d'exploration\n",
    "\n",
    "1. ‚úÖ Import des libraries\n",
    "2. ‚úÖ Connexion √† QuiverQuant\n",
    "3. ‚úÖ Congressional Trading - Tous les trades\n",
    "4. ‚úÖ Congressional Trading - Par ticker sp√©cifique\n",
    "5. ‚úÖ Senate vs House Trading\n",
    "6. ‚úÖ Insider Trading\n",
    "7. ‚úÖ WallStreetBets Sentiment\n",
    "8. ‚úÖ Analyse comparative\n",
    "9. ‚úÖ Nettoyage et standardisation\n",
    "10. ‚úÖ Export et int√©gration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc7580",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Import des Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27219a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Project root: c:\\project\\n8n-dashboard-v4\n",
      "üìÇ Paths ajout√©s: ['c:\\\\project\\\\n8n-dashboard-v4\\\\services', 'c:\\\\project\\\\n8n-dashboard-v4\\\\prod', 'c:\\\\project\\\\n8n-dashboard-v4']\n",
      "‚ö†Ô∏è Erreur import QuiverQuant: No module named 'quiverquant'\n",
      "   V√©rifier que les modules existent dans la branche _political_trading\n",
      "‚úÖ Libraries import√©es\n",
      "üìÖ Date/heure: 2026-01-06 11:05:43.998917\n",
      "üîê Token disponible: ‚ùå (module non trouv√©)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# D√©terminer le r√©pertoire racine du projet\n",
    "notebook_dir = Path(r'c:\\project\\n8n-dashboard-v4\\notebooks')\n",
    "project_root = notebook_dir.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Ajouter les chemins importants\n",
    "sys.path.insert(0, str(project_root / 'prod'))\n",
    "sys.path.insert(0, str(project_root / 'services'))\n",
    "\n",
    "print(f\"üìÇ Project root: {project_root}\")\n",
    "print(f\"üìÇ Paths ajout√©s: {sys.path[:3]}\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "# ‚úÖ IMPORT CONFIG - SINGLE SOURCE OF TRUTH\n",
    "try:\n",
    "    from config.companies_config import get_all_companies, COMPANIES_CONFIG\n",
    "    print(\"‚úÖ companies_config import√© avec succ√®s\")\n",
    "    \n",
    "    # Afficher les tickers configur√©s\n",
    "    companies = get_all_companies()\n",
    "    TICKERS = [c['ticker'] for c in companies]\n",
    "    print(f\"   üìä Tickers configur√©s: {TICKERS}\")\n",
    "    print(f\"   üìä Total: {len(TICKERS)} compagnies\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Erreur import companies_config: {e}\")\n",
    "    TICKERS = None\n",
    "\n",
    "# Importer le client QuiverQuant depuis la structure correcte\n",
    "try:\n",
    "    from quiverquant.quiverquant_client import QuiverQuantClient\n",
    "    from quiverquant.config import QUIVERQUANT_TOKEN\n",
    "    print(\"‚úÖ QuiverQuant modules import√©s avec succ√®s\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Erreur import QuiverQuant: {e}\")\n",
    "    print(\"   V√©rifier que les modules existent dans la branche _political_trading\")\n",
    "    QUIVERQUANT_TOKEN = None\n",
    "\n",
    "print(\"‚úÖ Libraries import√©es\")\n",
    "print(f\"üìÖ Date/heure: {datetime.now()}\")\n",
    "print(f\"üîê Token disponible: {'‚úÖ' if QUIVERQUANT_TOKEN else '‚ùå (module non trouv√©)'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e468b5a9",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Connexion √† QuiverQuant & Premi√®re Requ√™te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5cab16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîå Initialisation du client QuiverQuant...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'QuiverQuantClient' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialiser le client\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîå Initialisation du client QuiverQuant...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mQuiverQuantClient\u001b[49m(QUIVERQUANT_TOKEN)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Client pr√™t!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Premi√®re requ√™te: Congressional Trading\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'QuiverQuantClient' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialiser le client\n",
    "print(\"üîå Initialisation du client QuiverQuant...\")\n",
    "client = QuiverQuantClient(QUIVERQUANT_TOKEN)\n",
    "print(\"‚úÖ Client pr√™t!\")\n",
    "\n",
    "# ‚úÖ STEP 1: AFFICHER LA CONFIG\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìã CONFIGURATION: Tickers √† analyser\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìç Source: prod/config/companies_config.py\")\n",
    "print(f\"üìä Tickers ({len(TICKERS)}):\")\n",
    "for i, ticker in enumerate(TICKERS, 1):\n",
    "    company = next((c for c in companies if c['ticker'] == ticker), None)\n",
    "    if company:\n",
    "        print(f\"   {i:2d}. {ticker:6s} - {company['name']:30s} ({company['sector']})\")\n",
    "\n",
    "# Premi√®re requ√™te: Congressional Trading\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üì° STEP 1: Congressional Trading (Tous les trades r√©cents)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    df_congress = client.congress_trading()\n",
    "    print(f\"‚úÖ Succ√®s! {len(df_congress)} trades r√©cup√©r√©s\")\n",
    "    print(f\"\\nüìä Shape: {df_congress.shape}\")\n",
    "    print(f\"\\nüìã Colonnes: {list(df_congress.columns)}\")\n",
    "    print(f\"\\nüîç Premiers 3 trades:\")\n",
    "    print(df_congress.head(3))\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce90e92",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Exploration D√©taill√©e - Congressional Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc25be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ANALYSE CONGRESSIONAL TRADING\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ INFO G√âN√âRALES:\n",
      "   Nombre de trades: 1000\n",
      "   Date min: 2025-01-02 00:00:00\n",
      "   Date max: 2025-12-16 00:00:00\n",
      "\n",
      "2Ô∏è‚É£ TYPES DE DONN√âES:\n",
      "Representative             object\n",
      "BioGuideID                 object\n",
      "ReportDate         datetime64[ns]\n",
      "TransactionDate    datetime64[ns]\n",
      "Ticker                     object\n",
      "Transaction                object\n",
      "Range                      object\n",
      "House                      object\n",
      "Amount                     object\n",
      "Party                      object\n",
      "last_modified              object\n",
      "TickerType                 object\n",
      "Description                object\n",
      "ExcessReturn              float64\n",
      "PriceChange               float64\n",
      "SPYChange                 float64\n",
      "dtype: object\n",
      "\n",
      "3Ô∏è‚É£ VALEURS MANQUANTES:\n",
      "Description     976\n",
      "ExcessReturn     22\n",
      "PriceChange      22\n",
      "SPYChange        22\n",
      "dtype: int64\n",
      "\n",
      "4Ô∏è‚É£ STATISTIQUES DESCRIPTIVES:\n",
      "                       ReportDate             TransactionDate  ExcessReturn  \\\n",
      "count                        1000                        1000    978.000000   \n",
      "mean   2025-09-16 00:33:07.200000  2025-08-22 09:02:52.800000      1.315617   \n",
      "min           2025-01-08 00:00:00         2025-01-02 00:00:00    -80.619305   \n",
      "25%           2025-06-14 00:00:00         2025-05-13 00:00:00     -7.786981   \n",
      "50%           2025-11-21 00:00:00         2025-10-31 00:00:00     -0.019976   \n",
      "75%           2025-12-11 00:00:00         2025-11-13 00:00:00      7.453478   \n",
      "max           2025-12-29 00:00:00         2025-12-16 00:00:00    141.611603   \n",
      "std                           NaN                         NaN     22.647136   \n",
      "\n",
      "       PriceChange   SPYChange  \n",
      "count   978.000000  978.000000  \n",
      "mean      8.022733    6.707116  \n",
      "min     -69.501695   -8.106182  \n",
      "25%      -2.545633   -0.027112  \n",
      "50%       3.010525    1.802680  \n",
      "75%      11.752990   12.761620  \n",
      "max     166.423237   37.248763  \n",
      "std      24.274091    8.751641  \n",
      "\n",
      "5Ô∏è‚É£ POLITICIENS UNIQUES: 43\n",
      "   Top 10:\n",
      "Representative\n",
      "John Boozman                 178\n",
      "Gilbert Cisneros             175\n",
      "Lisa Mcclain                 126\n",
      "Markwayne Mullin              89\n",
      "Julie Johnson                 65\n",
      "Shelley Moore Capito          59\n",
      "Tommy Tuberville              27\n",
      "Sheldon Whitehouse            26\n",
      "David H. McCormick            25\n",
      "Richard Dean Dr Mccormick     25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "6Ô∏è‚É£ TICKERS UNIQUES: 465\n",
      "   Top 10:\n",
      "Ticker\n",
      "MSFT     26\n",
      "BITB     22\n",
      "GOOGL    18\n",
      "NVDA     15\n",
      "AAPL     15\n",
      "GOOG     12\n",
      "UNH      12\n",
      "LLY      11\n",
      "JPM      10\n",
      "META     10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "7Ô∏è‚É£ TYPES DE TRANSACTIONS:\n",
      "Transaction\n",
      "Purchase          468\n",
      "Sale              271\n",
      "Sale (Partial)    138\n",
      "Sale (Full)       121\n",
      "Exchange            2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä STEP 3: ANALYSE CONGRESSIONAL TRADING - Align√© avec Config\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ‚úÖ Toujours utiliser df_congress_filtered (d√©j√† filtr√© par tickers configur√©s)\n",
    "df_analysis = df_congress_filtered.copy()\n",
    "\n",
    "print(f\"\\nüìç Source: companies_config.py ({len(TICKERS)} tickers)\")\n",
    "print(f\"üìä Donn√©es: Congressional Trading (filtered)\\n\")\n",
    "\n",
    "# Info g√©n√©rales\n",
    "print(\"1Ô∏è‚É£ INFO G√âN√âRALES:\")\n",
    "print(f\"   Nombre de trades: {len(df_analysis)}\")\n",
    "print(f\"   Nombre de tickers configur√©s avec donn√©es: {df_analysis['Ticker'].nunique()}/{len(TICKERS)}\")\n",
    "if 'TransactionDate' in df_analysis.columns:\n",
    "    df_analysis_dt = df_analysis.copy()\n",
    "    df_analysis_dt['TransactionDate'] = pd.to_datetime(df_analysis_dt['TransactionDate'])\n",
    "    print(f\"   Date min: {df_analysis_dt['TransactionDate'].min()}\")\n",
    "    print(f\"   Date max: {df_analysis_dt['TransactionDate'].max()}\")\n",
    "\n",
    "# Types de donn√©es\n",
    "print(\"\\n2Ô∏è‚É£ TYPES DE DONN√âES:\")\n",
    "print(df_analysis.dtypes)\n",
    "\n",
    "# Valeurs manquantes\n",
    "print(\"\\n3Ô∏è‚É£ VALEURS MANQUANTES:\")\n",
    "missing = df_analysis.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"‚úÖ Aucune valeur manquante!\")\n",
    "\n",
    "# Statistiques descriptives\n",
    "print(\"\\n4Ô∏è‚É£ STATISTIQUES DESCRIPTIVES:\")\n",
    "print(df_analysis.describe())\n",
    "\n",
    "# Politiciens uniques\n",
    "if 'Representative' in df_analysis.columns:\n",
    "    print(f\"\\n5Ô∏è‚É£ POLITICIENS UNIQUES: {df_analysis['Representative'].nunique()}\")\n",
    "    print(\"   Top 10:\")\n",
    "    print(df_analysis['Representative'].value_counts().head(10))\n",
    "\n",
    "# Tickers (should be subset of TICKERS)\n",
    "if 'Ticker' in df_analysis.columns:\n",
    "    print(f\"\\n6Ô∏è‚É£ TICKERS DANS DONN√âES (from config):\")\n",
    "    tickers_in_data = df_analysis['Ticker'].unique()\n",
    "    tickers_missing = set(TICKERS) - set(tickers_in_data)\n",
    "    print(f\"   ‚úÖ Pr√©sents: {len(tickers_in_data)}\")\n",
    "    print(df_analysis['Ticker'].value_counts().sort_index())\n",
    "    if tickers_missing:\n",
    "        print(f\"\\n   ‚ö†Ô∏è Pas de donn√©es: {', '.join(sorted(tickers_missing))}\")\n",
    "\n",
    "# Types de transactions\n",
    "if 'Transaction' in df_analysis.columns:\n",
    "    print(f\"\\n7Ô∏è‚É£ TYPES DE TRANSACTIONS:\")\n",
    "    print(df_analysis['Transaction'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917bdd9c",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Test Sp√©cifique - Trades Tesla par Congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823895c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç TEST TRADES PAR TICKER SP√âCIFIQUE\n",
      "======================================================================\n",
      "Note: L'endpoint par ticker retourne des erreurs JSON.\n",
      "Solution: Filtrer le DataFrame complet r√©cup√©r√© pr√©c√©demment\n",
      "\n",
      "\n",
      "üìä Analyse de TSLA:\n",
      "   ‚úÖ 2 trades trouv√©s dans df_congress\n",
      "   üìã Premiers trades:\n",
      "      - Gilbert Cisneros: Purchase on 2025-11-18 00:00:00\n",
      "      - Lisa Mcclain: Sale on 2025-10-31 00:00:00\n",
      "   üìà BUY: 1 | SELL: 1\n",
      "   üìÖ Date range: 2025-10-31 ‚Üí 2025-11-18\n",
      "\n",
      "üìä Analyse de NVDA:\n",
      "   ‚úÖ 15 trades trouv√©s dans df_congress\n",
      "   üìã Premiers trades:\n",
      "      - Dwight Evans: Purchase on 2025-11-21 00:00:00\n",
      "      - Gilbert Cisneros: Purchase on 2025-11-18 00:00:00\n",
      "      - Lisa Mcclain: Sale on 2025-10-31 00:00:00\n",
      "   üìà BUY: 9 | SELL: 1\n",
      "   üìÖ Date range: 2025-01-06 ‚Üí 2025-11-21\n",
      "\n",
      "üìä Analyse de MSFT:\n",
      "   ‚úÖ 26 trades trouv√©s dans df_congress\n",
      "   üìã Premiers trades:\n",
      "      - Dwight Evans: Sale on 2025-11-21 00:00:00\n",
      "      - Cleo Fields: Purchase on 2025-12-11 00:00:00\n",
      "      - Cleo Fields: Purchase on 2025-12-11 00:00:00\n",
      "   üìà BUY: 12 | SELL: 2\n",
      "   üìÖ Date range: 2025-01-03 ‚Üí 2025-12-11\n",
      "\n",
      "üìä Analyse de META:\n",
      "   ‚úÖ 10 trades trouv√©s dans df_congress\n",
      "   üìã Premiers trades:\n",
      "      - Jonathan Jackson: Sale on 2025-11-11 00:00:00\n",
      "      - Shelley Moore Capito: Purchase on 2025-11-13 00:00:00\n",
      "      - Lisa Mcclain: Sale on 2025-10-31 00:00:00\n",
      "   üìà BUY: 8 | SELL: 2\n",
      "   üìÖ Date range: 2025-03-26 ‚Üí 2025-11-13\n",
      "\n",
      "üìä Analyse de AAPL:\n",
      "   ‚úÖ 15 trades trouv√©s dans df_congress\n",
      "   üìã Premiers trades:\n",
      "      - Gilbert Cisneros: Purchase on 2025-11-18 00:00:00\n",
      "      - Richard Dean Dr Mccormick: Purchase on 2025-11-05 00:00:00\n",
      "      - Debbie Dingell: Sale on 2025-11-24 00:00:00\n",
      "   üìà BUY: 3 | SELL: 2\n",
      "   üìÖ Date range: 2025-01-10 ‚Üí 2025-11-24\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Test termin√©\n",
      "\n",
      "üí° Solution utilis√©e: Filtrage du DataFrame complet (m√©thode recommand√©e)\n",
      "   car l'endpoint /live/congresstrading/{ticker} retourne des erreurs JSON.\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç STEP 2: Filtrer Donn√©es par Tickers Configur√©s\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìç Source: companies_config.py ‚Üí TICKERS list\")\n",
    "print(f\"   Filtrer df_congress pour ne garder que les {len(TICKERS)} tickers configur√©s\\n\")\n",
    "\n",
    "# Tickers de la config\n",
    "print(f\"‚úÖ Tickers √† analyser (from config): {TICKERS}\\n\")\n",
    "\n",
    "# Filtrer df_congress pour tickers configur√©s\n",
    "df_congress_filtered = df_congress[df_congress['Ticker'].isin(TICKERS)].copy()\n",
    "\n",
    "print(f\"üìä AVANT filtrage: {len(df_congress)} trades totaux\")\n",
    "print(f\"üìä APR√àS filtrage: {len(df_congress_filtered)} trades pour {len(TICKERS)} tickers configur√©s\")\n",
    "\n",
    "# Analyser par ticker\n",
    "print(f\"\\nüìà DISTRIBUTION PAR TICKER (configur√©s):\")\n",
    "ticker_counts = df_congress_filtered['Ticker'].value_counts().sort_index()\n",
    "for ticker in TICKERS:\n",
    "    count = ticker_counts.get(ticker, 0)\n",
    "    company = next((c for c in companies if c['ticker'] == ticker), {})\n",
    "    sector = company.get('sector', 'N/A')\n",
    "    status = \"‚úÖ\" if count > 0 else \"‚ö†Ô∏è\"\n",
    "    print(f\"   {status} {ticker:6s} ({sector:15s}): {count:3d} trades\")\n",
    "\n",
    "# D√©tails pour tickers avec donn√©es\n",
    "print(f\"\\nüìã D√âTAILS DES TRADES PAR TICKER:\")\n",
    "for ticker in TICKERS:\n",
    "    df_ticker = df_congress_filtered[df_congress_filtered['Ticker'] == ticker]\n",
    "    \n",
    "    if len(df_ticker) > 0:\n",
    "        print(f\"\\n   {ticker}:\")\n",
    "        \n",
    "        # Statistiques BUY/SELL\n",
    "        if 'Transaction' in df_ticker.columns:\n",
    "            buys = (df_ticker['Transaction'].str.contains('Purchase', case=False, na=False)).sum()\n",
    "            sells = (df_ticker['Transaction'].str.contains('Sale', case=False, na=False)).sum()\n",
    "            print(f\"      üìà BUY: {buys} | SELL: {sells}\")\n",
    "            \n",
    "        # Date range\n",
    "        if 'TransactionDate' in df_ticker.columns:\n",
    "            df_ticker_copy = df_ticker.copy()\n",
    "            df_ticker_copy['TransactionDate'] = pd.to_datetime(df_ticker_copy['TransactionDate'])\n",
    "            date_min = df_ticker_copy['TransactionDate'].min()\n",
    "            date_max = df_ticker_copy['TransactionDate'].max()\n",
    "            print(f\"      üìÖ Date range: {date_min.date()} ‚Üí {date_max.date()}\")\n",
    "        \n",
    "        # Top politicians\n",
    "        if 'Representative' in df_ticker.columns:\n",
    "            top_rep = df_ticker['Representative'].value_counts().head(1)\n",
    "            if len(top_rep) > 0:\n",
    "                print(f\"      üë§ Top trader: {top_rep.index[0]} ({top_rep.values[0]} trades)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Filtrage termin√© - Donn√©es align√©es avec companies_config\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba252db2",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Senate vs House Trading (Donn√©es S√©par√©es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664102ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèõÔ∏è SENATE vs HOUSE TRADING\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ SENATE TRADING:\n",
      "‚úÖ 5000 trades du S√©nat\n",
      "   Colonnes: ['Senator', 'BioGuideID', 'Date', 'Ticker', 'Transaction', 'Range', 'Amount', 'last_modified']\n",
      "   \n",
      "   Premiers 3:\n",
      "                     Senator BioGuideID       Date Ticker Transaction  \\\n",
      "0  A. Mitchell Jr. McConnell    M000355 2025-12-01    WFC    Purchase   \n",
      "1         David H. McCormick    M001243 2025-11-28   BITB    Purchase   \n",
      "2         David H. McCormick    M001243 2025-11-26   BITB    Purchase   \n",
      "\n",
      "                Range   Amount last_modified  \n",
      "0    $1,001 - $15,000   1001.0    2025-12-19  \n",
      "1  $50,001 - $100,000  50001.0    2025-12-26  \n",
      "2  $50,001 - $100,000  50001.0    2025-12-26  \n",
      "\n",
      "2Ô∏è‚É£ HOUSE TRADING:\n",
      "‚úÖ 5000 trades du S√©nat\n",
      "   Colonnes: ['Senator', 'BioGuideID', 'Date', 'Ticker', 'Transaction', 'Range', 'Amount', 'last_modified']\n",
      "   \n",
      "   Premiers 3:\n",
      "                     Senator BioGuideID       Date Ticker Transaction  \\\n",
      "0  A. Mitchell Jr. McConnell    M000355 2025-12-01    WFC    Purchase   \n",
      "1         David H. McCormick    M001243 2025-11-28   BITB    Purchase   \n",
      "2         David H. McCormick    M001243 2025-11-26   BITB    Purchase   \n",
      "\n",
      "                Range   Amount last_modified  \n",
      "0    $1,001 - $15,000   1001.0    2025-12-19  \n",
      "1  $50,001 - $100,000  50001.0    2025-12-26  \n",
      "2  $50,001 - $100,000  50001.0    2025-12-26  \n",
      "\n",
      "2Ô∏è‚É£ HOUSE TRADING:\n",
      "‚úÖ 5000 trades de la Chambre\n",
      "   Colonnes: ['Representative', 'BioGuideID', 'Date', 'Ticker', 'Transaction', 'Range', 'Amount', 'last_modified']\n",
      "   \n",
      "   Premiers 3:\n",
      "  Representative BioGuideID       Date Ticker Transaction              Range  \\\n",
      "0      Tim Moore    M001236 2025-12-16   CBRL    Purchase  $15,001 - $50,000   \n",
      "1    Cleo Fields    F000110 2025-12-15   GOOG    Purchase   $1,001 - $15,000   \n",
      "2    Cleo Fields    F000110 2025-12-15   SOUN        Sale   $1,001 - $15,000   \n",
      "\n",
      "    Amount last_modified  \n",
      "0  15001.0    2025-12-22  \n",
      "1   1001.0    2025-12-18  \n",
      "2   1001.0    2025-12-18  \n",
      "\n",
      "3Ô∏è‚É£ COMPARAISON:\n",
      "   Senate: 5000 trades\n",
      "   House: 5000 trades\n",
      "   Total Congress (combin√©): 1000 trades\n",
      "‚úÖ 5000 trades de la Chambre\n",
      "   Colonnes: ['Representative', 'BioGuideID', 'Date', 'Ticker', 'Transaction', 'Range', 'Amount', 'last_modified']\n",
      "   \n",
      "   Premiers 3:\n",
      "  Representative BioGuideID       Date Ticker Transaction              Range  \\\n",
      "0      Tim Moore    M001236 2025-12-16   CBRL    Purchase  $15,001 - $50,000   \n",
      "1    Cleo Fields    F000110 2025-12-15   GOOG    Purchase   $1,001 - $15,000   \n",
      "2    Cleo Fields    F000110 2025-12-15   SOUN        Sale   $1,001 - $15,000   \n",
      "\n",
      "    Amount last_modified  \n",
      "0  15001.0    2025-12-22  \n",
      "1   1001.0    2025-12-18  \n",
      "2   1001.0    2025-12-18  \n",
      "\n",
      "3Ô∏è‚É£ COMPARAISON:\n",
      "   Senate: 5000 trades\n",
      "   House: 5000 trades\n",
      "   Total Congress (combin√©): 1000 trades\n"
     ]
    }
   ],
   "source": [
    "print(\"üèõÔ∏è STEP 4: SENATE vs HOUSE TRADING - Filtr√©s par Config\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìç Source: companies_config.py ({len(TICKERS)} tickers)\\n\")\n",
    "\n",
    "# Senate\n",
    "print(\"1Ô∏è‚É£ SENATE TRADING:\")\n",
    "try:\n",
    "    df_senate = client.senate_trading()\n",
    "    # ‚úÖ Filtrer par tickers configur√©s\n",
    "    df_senate_filtered = df_senate[df_senate['Ticker'].isin(TICKERS)].copy()\n",
    "    print(f\"   ‚úÖ Total: {len(df_senate)} trades\")\n",
    "    print(f\"   ‚úÖ Filtr√©s (config tickers): {len(df_senate_filtered)} trades\")\n",
    "    \n",
    "    if len(df_senate_filtered) > 0:\n",
    "        print(f\"   Colonnes: {list(df_senate_filtered.columns)}\")\n",
    "        print(f\"   Tickers avec donn√©es: {df_senate_filtered['Ticker'].unique().tolist()}\")\n",
    "        print(f\"\\n   Premiers 3:\")\n",
    "        print(df_senate_filtered.head(3))\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur: {e}\")\n",
    "    df_senate_filtered = None\n",
    "\n",
    "# House\n",
    "print(\"\\n2Ô∏è‚É£ HOUSE TRADING:\")\n",
    "try:\n",
    "    df_house = client.house_trading()\n",
    "    # ‚úÖ Filtrer par tickers configur√©s\n",
    "    df_house_filtered = df_house[df_house['Ticker'].isin(TICKERS)].copy()\n",
    "    print(f\"   ‚úÖ Total: {len(df_house)} trades\")\n",
    "    print(f\"   ‚úÖ Filtr√©s (config tickers): {len(df_house_filtered)} trades\")\n",
    "    \n",
    "    if len(df_house_filtered) > 0:\n",
    "        print(f\"   Colonnes: {list(df_house_filtered.columns)}\")\n",
    "        print(f\"   Tickers avec donn√©es: {df_house_filtered['Ticker'].unique().tolist()}\")\n",
    "        print(f\"\\n   Premiers 3:\")\n",
    "        print(df_house_filtered.head(3))\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur: {e}\")\n",
    "    df_house_filtered = None\n",
    "\n",
    "# Comparaison\n",
    "print(\"\\n3Ô∏è‚É£ COMPARAISON (apr√®s filtrage par config):\")\n",
    "senate_count = len(df_senate_filtered) if df_senate_filtered is not None else 0\n",
    "house_count = len(df_house_filtered) if df_house_filtered is not None else 0\n",
    "congress_count = len(df_congress_filtered)\n",
    "\n",
    "print(f\"   Senate:       {senate_count:4d} trades\")\n",
    "print(f\"   House:        {house_count:4d} trades\")\n",
    "print(f\"   Congress*:    {congress_count:4d} trades (combined)\")\n",
    "print(f\"   (* from earlier retrieval, all {len(TICKERS)} tickers)\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ BREAKDOWN PAR CHAMBER:\")\n",
    "for ticker in TICKERS:\n",
    "    senate_trades = len(df_senate_filtered[df_senate_filtered['Ticker'] == ticker]) if df_senate_filtered is not None else 0\n",
    "    house_trades = len(df_house_filtered[df_house_filtered['Ticker'] == ticker]) if df_house_filtered is not None else 0\n",
    "    congress_trades = len(df_congress_filtered[df_congress_filtered['Ticker'] == ticker])\n",
    "    \n",
    "    if congress_trades > 0:\n",
    "        print(f\"   {ticker}: Senate={senate_trades:2d} | House={house_trades:2d} | Total={congress_trades:2d}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ec6f9",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Insider Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e9d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëî INSIDER TRADING DATA\n",
      "======================================================================\n",
      "üì° Fetching: https://api.quiverquant.com/beta/live/insiders\n",
      "‚ùå Erreur: If using all scalar values, you must pass an index\n",
      "‚ùå Erreur: If using all scalar values, you must pass an index\n"
     ]
    }
   ],
   "source": [
    "print(\"üëî STEP 5: INSIDER TRADING - Filtr√©s par Config\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìç Source: companies_config.py ({len(TICKERS)} tickers)\\n\")\n",
    "\n",
    "try:\n",
    "    df_insiders = client.insiders()\n",
    "    # ‚úÖ Filtrer par tickers configur√©s\n",
    "    df_insiders_filtered = df_insiders[df_insiders['Ticker'].isin(TICKERS)].copy()\n",
    "    \n",
    "    print(f\"‚úÖ Total insiders: {len(df_insiders)} trades\")\n",
    "    print(f\"‚úÖ Filtr√©s (config tickers): {len(df_insiders_filtered)} trades\")\n",
    "    \n",
    "    print(f\"\\nüìä Shape: {df_insiders_filtered.shape}\")\n",
    "    print(f\"\\nüìã Colonnes: {list(df_insiders_filtered.columns)}\")\n",
    "    \n",
    "    print(f\"\\nüîç Premiers 5 insiders:\")\n",
    "    print(df_insiders_filtered.head(5))\n",
    "    \n",
    "    # Analyze\n",
    "    if 'Ticker' in df_insiders_filtered.columns:\n",
    "        print(f\"\\nüìà DISTRIBUTION PAR TICKER (configur√©s):\")\n",
    "        for ticker in TICKERS:\n",
    "            count = len(df_insiders_filtered[df_insiders_filtered['Ticker'] == ticker])\n",
    "            if count > 0:\n",
    "                print(f\"   {ticker}: {count} trades\")\n",
    "    \n",
    "    if 'Relationship' in df_insiders_filtered.columns:\n",
    "        print(f\"\\nüë§ TYPES DE RELATIONSHIPS (configur√©s):\")\n",
    "        print(df_insiders_filtered['Relationship'].value_counts().head(10))\n",
    "    \n",
    "    # Transaction types\n",
    "    if 'TransactionType' in df_insiders_filtered.columns:\n",
    "        print(f\"\\nüìä TYPES DE TRANSACTIONS (insider):\")\n",
    "        print(df_insiders_filtered['TransactionType'].value_counts())\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur: {e}\")\n",
    "    df_insiders_filtered = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b3428c",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ WallStreetBets Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea819b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ WALLSTREETBETS SENTIMENT\n",
      "======================================================================\n",
      "‚ö†Ô∏è Note: Cet endpoint peut n√©cessiter un abonnement premium\n",
      "\n",
      "üîç Tentative: Yesterday's data\n",
      "üì° Fetching: https://api.quiverquant.com/beta/live/wallstreetbets\n",
      "   ‚ùå Format r√©ponse invalide (possiblement vide ou premium)\n",
      "üîç Tentative: Date range (last 7 days)\n",
      "üì° Fetching: https://api.quiverquant.com/beta/live/wallstreetbets?count_all=true&date_from=20251226&date_to=2026-01-02\n",
      "   ‚ùå Format r√©ponse invalide (possiblement vide ou premium)\n",
      "üîç Tentative: Date range (last 7 days)\n",
      "üì° Fetching: https://api.quiverquant.com/beta/live/wallstreetbets?count_all=true&date_from=20251226&date_to=2026-01-02\n",
      "   ‚ùå Format r√©ponse invalide (possiblement vide ou premium)\n",
      "üîç Tentative: All data (d√©faut)\n",
      "üì° Fetching: https://api.quiverquant.com/beta/live/wallstreetbets?count_all=true\n",
      "   ‚ùå Format r√©ponse invalide (possiblement vide ou premium)\n",
      "üîç Tentative: All data (d√©faut)\n",
      "üì° Fetching: https://api.quiverquant.com/beta/live/wallstreetbets?count_all=true\n",
      "   ‚ùå Format r√©ponse invalide (possiblement vide ou premium)\n",
      "\n",
      "======================================================================\n",
      "‚ö†Ô∏è ENDPOINT WALLSTREETBETS NON DISPONIBLE\n",
      "======================================================================\n",
      "\n",
      "Raisons possibles:\n",
      "   ‚úì Endpoint n√©cessite abonnement premium\n",
      "   ‚úì R√©ponse API vide ou format diff√©rent\n",
      "   ‚úì Donn√©es pas disponibles pour le compte actuel (bibep)\n",
      "\n",
      "Solution:\n",
      "   - V√©rifier abonnement sur quiverquant.com\n",
      "   - Contacter chris@quiverquant.com pour upgrade\n",
      "   - Les endpoints Congressional/Senate/House fonctionnent correctement ‚úÖ\n",
      "\n",
      "Alternative:\n",
      "   - Utiliser reddit API directement\n",
      "   - Scraper r/wallstreetbets manuellement\n",
      "   - Focus sur political trading data (disponible)\n",
      "    \n",
      "   ‚ùå Format r√©ponse invalide (possiblement vide ou premium)\n",
      "\n",
      "======================================================================\n",
      "‚ö†Ô∏è ENDPOINT WALLSTREETBETS NON DISPONIBLE\n",
      "======================================================================\n",
      "\n",
      "Raisons possibles:\n",
      "   ‚úì Endpoint n√©cessite abonnement premium\n",
      "   ‚úì R√©ponse API vide ou format diff√©rent\n",
      "   ‚úì Donn√©es pas disponibles pour le compte actuel (bibep)\n",
      "\n",
      "Solution:\n",
      "   - V√©rifier abonnement sur quiverquant.com\n",
      "   - Contacter chris@quiverquant.com pour upgrade\n",
      "   - Les endpoints Congressional/Senate/House fonctionnent correctement ‚úÖ\n",
      "\n",
      "Alternative:\n",
      "   - Utiliser reddit API directement\n",
      "   - Scraper r/wallstreetbets manuellement\n",
      "   - Focus sur political trading data (disponible)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(\"üí¨ STEP 6: WALLSTREETBETS SENTIMENT - Filtr√©s par Config\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìç Source: companies_config.py ({len(TICKERS)} tickers)\\n\")\n",
    "print(\"‚ö†Ô∏è Note: Cet endpoint peut n√©cessiter un abonnement premium\\n\")\n",
    "\n",
    "# Essayer diff√©rentes m√©thodes selon la documentation\n",
    "methods = [\n",
    "    (\"Yesterday's data\", lambda: client.wallstreetbets(yesterday=True)),\n",
    "    (\"Date range (last 7 days)\", lambda: client.wallstreetbets(\n",
    "        date_from=(datetime.now() - timedelta(days=7)).strftime(\"%Y-%m-%d\"),\n",
    "        date_to=datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    )),\n",
    "    (\"All data (d√©faut)\", lambda: client.wallstreetbets()),\n",
    "]\n",
    "\n",
    "df_wsb = None\n",
    "df_wsb_filtered = None\n",
    "success = False\n",
    "\n",
    "for method_name, method_func in methods:\n",
    "    print(f\"üîç Tentative: {method_name}\")\n",
    "    try:\n",
    "        df_wsb = method_func()\n",
    "        if df_wsb is not None and len(df_wsb) > 0:\n",
    "            # ‚úÖ Filtrer par tickers configur√©s\n",
    "            df_wsb_filtered = df_wsb[df_wsb['Ticker'].isin(TICKERS)].copy()\n",
    "            print(f\"   ‚úÖ Succ√®s! {len(df_wsb)} mentions trouv√©es\")\n",
    "            print(f\"   ‚úÖ Filtr√©s (config tickers): {len(df_wsb_filtered)} mentions\")\n",
    "            success = True\n",
    "            break\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è R√©ponse vide\")\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if \"Upgrade your subscription\" in error_msg:\n",
    "            print(f\"   ‚ùå Premium requis: {error_msg[:60]}\")\n",
    "        elif \"If using all scalar values\" in error_msg:\n",
    "            print(f\"   ‚ùå Format r√©ponse invalide (possiblement vide ou premium)\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå √âchec: {error_msg[:60]}\")\n",
    "\n",
    "if success and df_wsb_filtered is not None and len(df_wsb_filtered) > 0:\n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä ANALYSE DES DONN√âES WSB (filtr√©es par config)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nüìä Shape: {df_wsb_filtered.shape}\")\n",
    "    print(f\"üìã Colonnes: {list(df_wsb_filtered.columns)}\")\n",
    "    \n",
    "    print(f\"\\nüîç Premiers 5 mentions:\")\n",
    "    print(df_wsb_filtered.head(5))\n",
    "    \n",
    "    # Analyze\n",
    "    if 'Ticker' in df_wsb_filtered.columns:\n",
    "        print(f\"\\nüìà TOP TICKERS MENTIONN√âS (configur√©s):\")\n",
    "        print(df_wsb_filtered['Ticker'].value_counts().sort_index())\n",
    "        \n",
    "    # Date range\n",
    "    if 'Date' in df_wsb_filtered.columns:\n",
    "        print(f\"\\nüìÖ DATE RANGE:\")\n",
    "        print(f\"   Min: {df_wsb_filtered['Date'].min()}\")\n",
    "        print(f\"   Max: {df_wsb_filtered['Date'].max()}\")\n",
    "    \n",
    "    # Sentiment analysis (si disponible)\n",
    "    if 'Sentiment' in df_wsb_filtered.columns:\n",
    "        print(f\"\\nüòä SENTIMENT ANALYSIS (configur√©s):\")\n",
    "        print(df_wsb_filtered['Sentiment'].value_counts())\n",
    "    \n",
    "    # Mentions analysis (si disponible)\n",
    "    if 'Mentions' in df_wsb_filtered.columns:\n",
    "        print(f\"\\nüìä MENTIONS STATISTICS (configur√©s):\")\n",
    "        print(f\"   Total mentions: {df_wsb_filtered['Mentions'].sum()}\")\n",
    "        print(f\"   Average: {df_wsb_filtered['Mentions'].mean():.1f}\")\n",
    "        print(f\"   Median: {df_wsb_filtered['Mentions'].median():.1f}\")\n",
    "else:\n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(\"‚ö†Ô∏è ENDPOINT WALLSTREETBETS NON DISPONIBLE\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\"\"\n",
    "Raisons possibles:\n",
    "   ‚úì Endpoint n√©cessite abonnement premium\n",
    "   ‚úì R√©ponse API vide ou format diff√©rent\n",
    "   ‚úì Donn√©es pas disponibles pour le compte actuel (bibep)\n",
    "\n",
    "Solution:\n",
    "   - V√©rifier abonnement sur quiverquant.com\n",
    "   - Contacter chris@quiverquant.com pour upgrade\n",
    "   - Les endpoints Congressional/Senate/House fonctionnent correctement ‚úÖ\n",
    "\n",
    "Alternative:\n",
    "   - Utiliser reddit API directement\n",
    "   - Scraper r/wallstreetbets manuellement\n",
    "   - Focus sur political trading data (disponible)\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756178fc",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Analyse Comparative & Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492cc6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ STEP 7: STANDARDISATION DES DONN√âES - Using Config\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìç Source: companies_config.py + Congressional Trading\\n\")\n",
    "\n",
    "# Cr√©er une version standardis√©e des congressional trades (d√©j√† filtr√©s)\n",
    "print(\"1Ô∏è‚É£ CONGRESSIONAL TRADES - NETTOYAGE & STANDARDISATION:\\n\")\n",
    "\n",
    "df_congress_clean = df_congress_filtered.copy()\n",
    "\n",
    "# Rename columns pour coh√©rence\n",
    "column_mapping = {\n",
    "    'Representative': 'politician_name',\n",
    "    'TransactionDate': 'transaction_date',\n",
    "    'ReportDate': 'report_date',\n",
    "    'Ticker': 'ticker',\n",
    "    'Transaction': 'transaction_type',\n",
    "    'Amount': 'amount',\n",
    "    'Chamber': 'chamber'\n",
    "}\n",
    "\n",
    "df_congress_clean = df_congress_clean.rename(columns={k: v for k, v in column_mapping.items() if k in df_congress_clean.columns})\n",
    "\n",
    "# Add source\n",
    "df_congress_clean['source'] = 'Congress (QuiverQuant)'\n",
    "df_congress_clean['data_type'] = 'political_trade'\n",
    "df_congress_clean['config_source'] = 'companies_config.py'\n",
    "\n",
    "print(f\"‚úÖ Colonnes standardis√©es: {list(df_congress_clean.columns)}\")\n",
    "print(f\"\\nüìã Aper√ßu (from config tickers):\")\n",
    "cols_to_show = [col for col in ['politician_name', 'transaction_date', 'ticker', 'transaction_type', 'config_source'] if col in df_congress_clean.columns]\n",
    "print(df_congress_clean[cols_to_show].head(5))\n",
    "\n",
    "# V√©rifier les types de transactions\n",
    "print(f\"\\nüìà TYPES DE TRANSACTIONS (avant standardisation):\")\n",
    "if 'transaction_type' in df_congress_clean.columns:\n",
    "    print(df_congress_clean['transaction_type'].value_counts())\n",
    "    \n",
    "# Mapper to BUY/SELL\n",
    "print(f\"\\nüîÑ MAPPING BUY/SELL (standardisation):\")\n",
    "buy_terms = ['Purchase', 'Buy']\n",
    "sell_terms = ['Sale', 'Sell']\n",
    "\n",
    "def normalize_transaction_type(val):\n",
    "    if pd.isna(val):\n",
    "        return val\n",
    "    val_str = str(val).lower()\n",
    "    if any(term.lower() in val_str for term in buy_terms):\n",
    "        return 'BUY'\n",
    "    elif any(term.lower() in val_str for term in sell_terms):\n",
    "        return 'SELL'\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "df_congress_clean['transaction_type_normalized'] = df_congress_clean['transaction_type'].apply(normalize_transaction_type)\n",
    "\n",
    "print(\"Avant mapping:\", df_congress_clean['transaction_type'].unique()[:5])\n",
    "print(\"Apr√®s mapping:\", df_congress_clean['transaction_type_normalized'].unique())\n",
    "print(\"\\nComptage apr√®s mapping:\")\n",
    "print(df_congress_clean['transaction_type_normalized'].value_counts())\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£ VALIDATION: V√©rifier que tous tickers sont dans config\")\n",
    "unique_tickers_in_data = df_congress_clean['ticker'].unique()\n",
    "missing_from_config = set(unique_tickers_in_data) - set(TICKERS)\n",
    "if missing_from_config:\n",
    "    print(f\"‚ö†Ô∏è ERREUR: Tickers non trouv√©s dans config: {missing_from_config}\")\n",
    "else:\n",
    "    print(f\"‚úÖ OK: Tous les tickers dans donn√©es sont dans companies_config.py\")\n",
    "    print(f\"   Tickers dans donn√©es: {sorted(unique_tickers_in_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195bc001",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Statistiques Descriptives Compl√®tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875252f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä STEP 8: R√âSUM√â COMPLET DES DONN√âES - Config-Driven\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìç Source: companies_config.py ({len(TICKERS)} tickers)\\n\")\n",
    "\n",
    "summary = {\n",
    "    \"source\": {\n",
    "        \"config_file\": \"prod/config/companies_config.py\",\n",
    "        \"tickers\": TICKERS,\n",
    "        \"total_tickers\": len(TICKERS),\n",
    "    },\n",
    "    \"Congressional Trading\": {\n",
    "        \"count\": len(df_congress_filtered),\n",
    "        \"columns\": list(df_congress_filtered.columns),\n",
    "        \"unique_tickers\": df_congress_filtered['Ticker'].nunique() if 'Ticker' in df_congress_filtered.columns else 0,\n",
    "        \"tickers_in_data\": sorted(df_congress_filtered['Ticker'].unique().tolist()) if 'Ticker' in df_congress_filtered.columns else [],\n",
    "        \"politicians\": df_congress_filtered['Representative'].nunique() if 'Representative' in df_congress_filtered.columns else 'N/A',\n",
    "    },\n",
    "    \"Senate Trading\": {\n",
    "        \"count\": len(df_senate_filtered) if df_senate_filtered is not None else 0,\n",
    "        \"columns\": list(df_senate_filtered.columns) if df_senate_filtered is not None else [],\n",
    "        \"unique_tickers\": df_senate_filtered['Ticker'].nunique() if df_senate_filtered is not None and 'Ticker' in df_senate_filtered.columns else 0,\n",
    "    },\n",
    "    \"House Trading\": {\n",
    "        \"count\": len(df_house_filtered) if df_house_filtered is not None else 0,\n",
    "        \"columns\": list(df_house_filtered.columns) if df_house_filtered is not None else [],\n",
    "        \"unique_tickers\": df_house_filtered['Ticker'].nunique() if df_house_filtered is not None and 'Ticker' in df_house_filtered.columns else 0,\n",
    "    },\n",
    "    \"Insider Trading\": {\n",
    "        \"count\": len(df_insiders_filtered) if df_insiders_filtered is not None else 0,\n",
    "        \"columns\": list(df_insiders_filtered.columns) if df_insiders_filtered is not None else [],\n",
    "        \"unique_tickers\": df_insiders_filtered['Ticker'].nunique() if df_insiders_filtered is not None and 'Ticker' in df_insiders_filtered.columns else 0,\n",
    "    },\n",
    "    \"WSB Sentiment\": {\n",
    "        \"count\": len(df_wsb_filtered) if df_wsb_filtered is not None else 0,\n",
    "        \"columns\": list(df_wsb_filtered.columns) if df_wsb_filtered is not None else [],\n",
    "        \"unique_tickers\": df_wsb_filtered['Ticker'].nunique() if df_wsb_filtered is not None and 'Ticker' in df_wsb_filtered.columns else 0,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display summary\n",
    "print(\"üè¢ CONFIGURATION (source of truth):\")\n",
    "print(f\"   File: {summary['source']['config_file']}\")\n",
    "print(f\"   Total tickers: {summary['source']['total_tickers']}\")\n",
    "print(f\"   Tickers: {', '.join(summary['source']['tickers'][:5])}... ({len(TICKERS)} total)\")\n",
    "\n",
    "print(\"\\nüìä DATA SUMMARY (filtr√©s par config):\")\n",
    "for source, info in summary.items():\n",
    "    if source == 'source':\n",
    "        continue\n",
    "    print(f\"\\n   {source}:\")\n",
    "    for key, val in info.items():\n",
    "        if key == 'columns':\n",
    "            if val:\n",
    "                print(f\"      {key}: {', '.join(val[:3])}... ({len(val)} total)\")\n",
    "        elif key == 'tickers_in_data':\n",
    "            print(f\"      {key}: {val}\")\n",
    "        else:\n",
    "            print(f\"      {key}: {val}\")\n",
    "\n",
    "# Save summary to JSON\n",
    "summary_path = Path(\"c:/n8n-local-stack/local_files/smart_money/quiverquant_data_summary.json\")\n",
    "summary_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "    \n",
    "print(f\"\\n‚úÖ R√©sum√© sauvegard√©: {summary_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ TOUTES LES DONN√âES SONT FILTR√âES PAR companies_config.py\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e1b08",
   "metadata": {},
   "source": [
    "## üîü Export & Int√©gration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c5c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üíæ STEP 9: EXPORT & INT√âGRATION - Config-Driven\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìç Source: companies_config.py ({len(TICKERS)} tickers)\\n\")\n",
    "\n",
    "# Export Congressional cleaned (d√©j√† filtr√©)\n",
    "export_path = Path(\"c:/n8n-local-stack/local_files/smart_money/congressional_trades_explored.csv\")\n",
    "export_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_congress_clean.to_csv(export_path, index=False)\n",
    "print(f\"‚úÖ Congressional trades export√©s: {export_path}\")\n",
    "print(f\"   Taille: {len(df_congress_clean)} lignes\")\n",
    "print(f\"   Tickers: {len(df_congress_clean['ticker'].unique())} uniques (from config)\")\n",
    "\n",
    "# Export as JSON\n",
    "json_path = Path(\"c:/n8n-local-stack/local_files/smart_money/congressional_trades_explored.json\")\n",
    "df_congress_clean.to_json(json_path, orient='records', date_format='iso', indent=2)\n",
    "print(f\"‚úÖ JSON export√©: {json_path}\")\n",
    "\n",
    "# Config-driven export (metadata)\n",
    "config_metadata = {\n",
    "    \"source_config\": \"prod/config/companies_config.py\",\n",
    "    \"tickers_analyzed\": TICKERS,\n",
    "    \"total_tickers\": len(TICKERS),\n",
    "    \"data_types\": {\n",
    "        \"congressional_trades\": {\n",
    "            \"count\": len(df_congress_clean),\n",
    "            \"tickers\": sorted(df_congress_clean['ticker'].unique().tolist()),\n",
    "            \"file\": str(export_path)\n",
    "        },\n",
    "        \"insider_trades\": {\n",
    "            \"count\": len(df_insiders_filtered) if df_insiders_filtered is not None else 0,\n",
    "            \"tickers\": sorted(df_insiders_filtered['Ticker'].unique().tolist()) if df_insiders_filtered is not None else [],\n",
    "        },\n",
    "        \"wsb_sentiment\": {\n",
    "            \"count\": len(df_wsb_filtered) if df_wsb_filtered is not None else 0,\n",
    "            \"tickers\": sorted(df_wsb_filtered['Ticker'].unique().tolist()) if df_wsb_filtered is not None else [],\n",
    "        }\n",
    "    },\n",
    "    \"export_timestamp\": datetime.now().isoformat(),\n",
    "    \"analysis_date\": \"2026-01-06\"\n",
    "}\n",
    "\n",
    "metadata_path = Path(\"c:/n8n-local-stack/local_files/smart_money/config_driven_analysis_metadata.json\")\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(config_metadata, f, indent=2, default=str)\n",
    "    \n",
    "print(f\"‚úÖ Config metadata export√©: {metadata_path}\")\n",
    "\n",
    "# R√©sum√© pour int√©gration\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìù R√âSUM√â POUR INT√âGRATION SMART MONEY (CONFIG-DRIVEN)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "‚úÖ CONFIG SOURCE: prod/config/companies_config.py\n",
    "   Total tickers: {len(TICKERS)}\n",
    "   Tickers: {', '.join(TICKERS[:5])}... (15 total)\n",
    "\n",
    "‚úÖ DONN√âES DISPONIBLES (filtr√©es par config):\n",
    "   1. Congressional Trading: {len(df_congress_clean)} trades\n",
    "   2. Senate Trading: {len(df_senate_filtered) if df_senate_filtered is not None else 0} trades\n",
    "   3. House Trading: {len(df_house_filtered) if df_house_filtered is not None else 0} trades\n",
    "   4. Insider Trading: {len(df_insiders_filtered) if df_insiders_filtered is not None else 0} trades\n",
    "   5. WallStreetBets Sentiment: {len(df_wsb_filtered) if df_wsb_filtered is not None else 0} mentions\n",
    "\n",
    "üìä QUALIT√â DES DONN√âES:\n",
    "   ‚úì Congressional: Excellent (dates, noms, tickers, transactions)\n",
    "   ‚úì Standardisation: Possible (BUY/SELL mapping)\n",
    "   ‚úì Config alignment: 100% (tous filtr√©s par companies_config.py)\n",
    "   ‚úì Int√©gration: Pr√™te pour Smart Money Tracker\n",
    "\n",
    "üîÑ COMMENT UTILISER:\n",
    "   1. Importer companies_config.py en haut de chaque script\n",
    "   2. Appeler get_all_companies() pour obtenir liste de tickers\n",
    "   3. Filtrer df[df['Ticker'].isin(TICKERS)] √† chaque √©tape\n",
    "   4. Assurer que toutes les analyses utilisent la m√™me config\n",
    "\n",
    "üí° EXEMPLES:\n",
    "   # ‚úÖ BON: Config-driven\n",
    "   from config.companies_config import get_all_companies\n",
    "   companies = get_all_companies()\n",
    "   TICKERS = [c['ticker'] for c in companies]\n",
    "   df_filtered = df[df['Ticker'].isin(TICKERS)]\n",
    "   \n",
    "   # ‚ùå MAUVAIS: Hardcoded\n",
    "   TICKERS = ['NVDA', 'MSFT', 'GOOGL', ...]  # Probl√®me!\n",
    "\n",
    "üîó PROCHAINES √âTAPES:\n",
    "   1. Int√©grer dans edgar_smart_money_analyzer.py (utiliser config)\n",
    "   2. Cr√©er signaux politiques (config-driven loop)\n",
    "   3. Combiner avec Smart Money metrics (maintenir config source)\n",
    "   4. Tester sur historical data (reproducible via config)\n",
    "\n",
    "‚ö†Ô∏è NOTES IMPORTANTES:\n",
    "   - Congressional data a des d√©lais de report (5-45 jours)\n",
    "   - Insider trades ont aussi des d√©lais r√©glementaires\n",
    "   - WSB sentiment est real-time mais bruyant\n",
    "   - √Ä combiner avec d'autres signaux pour meilleur signal\n",
    "   - TOUJOURS commencer par companies_config.py comme source of truth\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\n‚úÖ Notebook exploration compl√®te et CONFIG-DRIVEN!\")\n",
    "print(f\"üìÅ Fichiers g√©n√©r√©s:\")\n",
    "print(f\"   - {export_path}\")\n",
    "print(f\"   - {json_path}\")\n",
    "print(f\"   - {metadata_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b53ec",
   "metadata": {},
   "source": [
    "## üîç BONUS: Limitations de l'API & Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83bbdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è LIMITATIONS DE L'API QUIVERQUANT\n",
      "======================================================================\n",
      "\n",
      "‚ùå PROBL√àME #1: LIMITE DE 1000 R√âSULTATS\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Raison: Protection contre surcharge API (pagination)\n",
      "Cons√©quence: Seulement les 1000 trades R√âCENTS retourn√©s\n",
      "\n",
      "Analyse des dates:\n",
      "\n",
      "   Date min:     2025-01-02\n",
      "   Date max:     2025-12-16\n",
      "   Span:         348 jours (1.0 ans)\n",
      "   Trades/jour:  2.9\n",
      "\n",
      "\n",
      "‚ùå PROBL√àME #2: D√âLAI DE REPORTING (1 AN)\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Raison: D√©lais l√©gaux avant disclosure public\n",
      "- Congressional trades: 5 √† 45 jours apr√®s transaction\n",
      "- Insider trades: Jusqu'√† 45 jours apr√®s transaction\n",
      "- R√©sultat: Donn√©es actuelles = transactions de mois/ann√©es ant√©rieurs!\n",
      "\n",
      "Example du notebook:\n",
      "   Transaction date: 2025-11-21\n",
      "   Report date:      2025-12-29\n",
      "   D√©lai:            38 jours ‚úÖ Normal\n",
      "\n",
      "‚ùå PROBL√àME #3: \"1 AN\" SIGNIFIE QUOI?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "C'est PAS une limite de l'API, c'est:\n",
      "‚úì Fen√™tre temporelle des donn√©es disponibles\n",
      "‚úì 1000 r√©sultats les plus r√©cents = ~1 an de trades\n",
      "‚úì Au-del√†, faut utiliser des param√®tres pour historical data\n",
      "\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n",
      "üîß SOLUTIONS POUR AVOIR PLUS DE DONN√âES:\n",
      "\n",
      "\n",
      "1Ô∏è‚É£ PAGINATION (non impl√©ment√©e dans le client):\n",
      "\n",
      "   - Ajouter param√®tres: 'offset', 'limit'\n",
      "   - R√©cup√©rer blocs de 100-500 r√©sultats\n",
      "   - It√©rer pour avoir historique complet\n",
      "   Exemple URL:\n",
      "   /live/congresstrading?limit=100&offset=0\n",
      "   /live/congresstrading?limit=100&offset=100\n",
      "   /live/congresstrading?limit=100&offset=200\n",
      "   ... etc\n",
      "\n",
      "2Ô∏è‚É£ ENDPOINTS HISTORIQUES:\n",
      "\n",
      "   - /historical/congresstrading/{ticker}  (par ticker)\n",
      "   - /historical/senatetrading/{ticker}     (par ticker)\n",
      "   - /historical/housetrading/{ticker}      (par ticker)\n",
      "   \n",
      "   Avantage: Plus de donn√©es par ticker\n",
      "   Limitation: Faut conna√Ætre les tickers avance\n",
      "\n",
      "3Ô∏è‚É£ PARAM√àTRES DATE:\n",
      "\n",
      "   - date_from, date_to\n",
      "   - Certains endpoints supportent filters\n",
      "   - Permet de requ√™ter historique sp√©cifique\n",
      "\n",
      "4Ô∏è‚É£ CACHING LOCAL:\n",
      "\n",
      "   - Sauvegarder les 1000 r√©sultats en local\n",
      "   - Daily fetch = nouveaux trades seulement\n",
      "   - Accumulation historique progressive\n",
      "   - Solution recommand√©e pour production ‚úÖ\n",
      "\n",
      "\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"üìö APPENDIX: Comment les Autres Scripts Utilisent la Config\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "üîç SCAN DES SCRIPTS PRODUITS\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "1Ô∏è‚É£ analyze_all_sentiment.py\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Location: prod/analysis/analyze_all_sentiment.py (line 18)\n",
    "\n",
    "‚úÖ CONFIG USAGE:\n",
    "   from config.companies_config import get_all_companies\n",
    "   \n",
    "   def analyze_all_companies():\n",
    "       companies = get_all_companies()\n",
    "       \n",
    "       # Filtrer les compagnies publiques (avec options)\n",
    "       public_companies = [c for c in companies \n",
    "                          if c['ticker'] not in ['OPENAI', 'ANTHROPIC', 'COHERE', 'MISTRAL']]\n",
    "       \n",
    "       for i, company in enumerate(public_companies, 1):\n",
    "           ticker = company['ticker']\n",
    "           # Analyser chaque ticker\n",
    "\n",
    "‚úÖ PATTERN: Utilise get_all_companies(), filtrer publics vs priv√©s, it√©rer\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "2Ô∏è‚É£ collect_options.py\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Location: prod/collection/collect_options.py (line 32)\n",
    "\n",
    "‚úÖ CONFIG USAGE:\n",
    "   from prod.config.companies_config import get_all_companies\n",
    "   \n",
    "   def collect_all_options():\n",
    "       all_companies = get_all_companies()\n",
    "       \n",
    "       for ticker in [c['ticker'] for c in all_companies]:\n",
    "           # Collecte donn√©es options pour ce ticker\n",
    "\n",
    "‚úÖ PATTERN: Import config, extract TICKERS, boucle sur chacun\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "3Ô∏è‚É£ batch_loader_v2.py\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Location: prod/collection/batch_loader_v2.py (line 34)\n",
    "\n",
    "‚úÖ CONFIG USAGE:\n",
    "   from config.companies_config import get_all_companies\n",
    "   \n",
    "   def load_batch():\n",
    "       companies = get_all_companies()\n",
    "       \n",
    "       # Charger donn√©es batch pour tous les tickers\n",
    "\n",
    "‚úÖ PATTERN: Utilise companies_config pour d√©finir scope du batch\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "4Ô∏è‚É£ smart_money_analyzer.py\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Location: prod/analysis/smart_money_analyzer.py (line 287-301)\n",
    "\n",
    "‚úÖ CONFIG USAGE:\n",
    "   def analyze_smart_money(tickers_filter=None):\n",
    "       '''\n",
    "       Si tickers_filter is None:\n",
    "           Utiliser companies_config comme filtre par d√©faut\n",
    "       '''\n",
    "       if tickers_filter is None:\n",
    "           from prod.config.companies_config import COMPANIES_CONFIG\n",
    "           tickers_filter = [c['ticker'] for c in COMPANIES_CONFIG]\n",
    "       \n",
    "       # Analyser uniquement les tickers configur√©s\n",
    "\n",
    "‚úÖ PATTERN: Config en fallback si pas de param, garantit coh√©rence\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "5Ô∏è‚É£ merge_options_into_sentiment.py\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Location: prod/analysis/merge_options_into_sentiment.py (line 113-115)\n",
    "\n",
    "‚úÖ CONFIG USAGE:\n",
    "   print(f\"\\\\nüìã Mode MANUAL: Utilisation de companies_config.py\")\n",
    "   \n",
    "   if MANUAL_MODE:\n",
    "       companies = get_all_companies()\n",
    "       # Merge pour tous les tickers configur√©s\n",
    "\n",
    "‚úÖ PATTERN: Option explicite pour utiliser config (vs CSV)\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "üìä PATTERN G√âN√âRAL\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "Tous les scripts suivent ce pattern:\n",
    "\n",
    "   # 1. Import config\n",
    "   from config.companies_config import get_all_companies\n",
    "   \n",
    "   # 2. R√©cup√©rer les tickers configur√©s\n",
    "   companies = get_all_companies()\n",
    "   tickers = [c['ticker'] for c in companies]\n",
    "   \n",
    "   # 3. Filtrer ou boucler sur ces tickers\n",
    "   for ticker in tickers:\n",
    "       process(ticker)\n",
    "   \n",
    "   # 4. R√©sultats s'alignent automatiquement avec config\n",
    "\n",
    "‚úÖ AVANTAGE: Si on change companies_config.py, TOUS les scripts changent!\n",
    "   - Pas de hardcoded tickers\n",
    "   - Source of truth unique\n",
    "   - Easy maintenance\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "üî¥ ANTIPATTERNS √Ä √âVITER\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ùå MAUVAIS: Hardcoded tickers\n",
    "   TICKERS = ['NVDA', 'MSFT', 'GOOGL', 'META', ...]  # Hard √† maintenir!\n",
    "   \n",
    "‚ùå MAUVAIS: Pas de config usage\n",
    "   if ticker in ['NVDA', 'MSFT']:  # Pas de coh√©rence\n",
    "   \n",
    "‚ùå MAUVAIS: Config ignor√©e dans une boucle\n",
    "   for ticker in HARDCODED_LIST:  # Devrait √™tre [c['ticker'] for c in get_all_companies()]\n",
    "\n",
    "‚úÖ BON: Toujours utiliser companies_config comme source\n",
    "   companies = get_all_companies()  # Always start here\n",
    "   for c in companies:\n",
    "       process(c['ticker'])  # Uses config\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n‚úÖ CONFIG ARCHITECTURE REVIEW COMPLETE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a95498",
   "metadata": {},
   "source": [
    "## üí° Impl√©mentation: Solution de Caching Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d27a7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ SOLUTION: ACCUMULATION PROGRESSIVE\n",
      "======================================================================\n",
      "\n",
      "üìÅ Cache directory: c:\\n8n-local-stack\\local_files\\smart_money\\quiverquant_cache\n",
      "\n",
      "1Ô∏è‚É£ PREMI√àRE EX√âCUTION (pas de cache):\n",
      "üìù Pas de cache - cr√©er nouveau\n",
      "üì° Fetching: https://api.quiverquant.com/beta/live/congresstrading\n",
      "   ‚úÖ Saved: c:\\n8n-local-stack\\local_files\\smart_money\\quiverquant_cache\\congressional_trading_cache.parquet\n",
      "\n",
      "üìä Total historique: 1000 trades\n",
      "\n",
      "2Ô∏è‚É£ DEUXI√àME EX√âCUTION (avec cache):\n",
      "‚úÖ Cache valide (0 jours old)\n",
      "   Loaded: 1000 trades from cache\n",
      "\n",
      "======================================================================\n",
      "‚úÖ R√âSULTAT:\n",
      "\n",
      "Au lieu de:\n",
      "   - Fetch 1000 aujourd'hui\n",
      "   - Perte apr√®s 1 an (circular buffer)\n",
      "\n",
      "Maintenant:\n",
      "   - Fetch 1000 daily\n",
      "   - Accumule historique localement\n",
      "   - 1000 * 365 = 365,000 trades potentiels!\n",
      "   - Croissance progressive sans perte\n",
      "   \n",
      "Avantage: Apr√®s 1 an de collection, avoir ~365K trades\n",
      "         Puis utiliser /historical/{ticker} pour des tickers sp√©cifiques\n",
      "\n",
      "\n",
      "üìÅ Cache saved at: c:\\n8n-local-stack\\local_files\\smart_money\\quiverquant_cache\n"
     ]
    }
   ],
   "source": [
    "print(\"üîÑ SOLUTION: ACCUMULATION PROGRESSIVE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Simuler un cache accumulatif\n",
    "cache_dir = Path(\"c:/n8n-local-stack/local_files/smart_money/quiverquant_cache\")\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nüìÅ Cache directory: {cache_dir}\")\n",
    "\n",
    "# Fonction pour charger ou cr√©er cache\n",
    "def load_or_create_cache(source_name, max_age_days=1):\n",
    "    \"\"\"\n",
    "    Load cached data ou fetch new if too old\n",
    "    \"\"\"\n",
    "    cache_file = cache_dir / f\"{source_name}_cache.parquet\"\n",
    "    \n",
    "    if cache_file.exists():\n",
    "        # Check age\n",
    "        mod_time = datetime.fromtimestamp(cache_file.stat().st_mtime)\n",
    "        age = (datetime.now() - mod_time).days\n",
    "        \n",
    "        if age < max_age_days:\n",
    "            print(f\"‚úÖ Cache valide ({age} jours old)\")\n",
    "            return pd.read_parquet(cache_file), True\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Cache expir√© ({age} jours old)\")\n",
    "            return None, False\n",
    "    else:\n",
    "        print(f\"üìù Pas de cache - cr√©er nouveau\")\n",
    "        return None, False\n",
    "\n",
    "# Fonction pour sauvegarder avec historique\n",
    "def save_with_history(df_new, source_name, max_keep=5):\n",
    "    \"\"\"\n",
    "    Save new data and keep rotation of old caches\n",
    "    \"\"\"\n",
    "    cache_file = cache_dir / f\"{source_name}_cache.parquet\"\n",
    "    \n",
    "    # Si cache existe, charger et merger\n",
    "    if cache_file.exists():\n",
    "        df_old = pd.read_parquet(cache_file)\n",
    "        print(f\"   Old cache: {len(df_old)} lignes\")\n",
    "        \n",
    "        # Merger (√©viter duplicates)\n",
    "        df_merged = pd.concat([df_new, df_old]).drop_duplicates(\n",
    "            subset=['Representative', 'TransactionDate', 'Ticker'] if 'Representative' in df_new.columns else None,\n",
    "            keep='first'\n",
    "        )\n",
    "        print(f\"   After merge: {len(df_merged)} lignes\")\n",
    "    else:\n",
    "        df_merged = df_new\n",
    "        \n",
    "    # Save\n",
    "    df_merged.to_parquet(cache_file)\n",
    "    print(f\"   ‚úÖ Saved: {cache_file}\")\n",
    "    \n",
    "    # Rotate old backups (keep last 5)\n",
    "    backup_files = sorted(cache_dir.glob(f\"{source_name}_backup_*.parquet\"))\n",
    "    for f in backup_files[:-max_keep]:\n",
    "        f.unlink()\n",
    "        \n",
    "    return df_merged\n",
    "\n",
    "# TEST\n",
    "print(\"\\n1Ô∏è‚É£ PREMI√àRE EX√âCUTION (pas de cache):\")\n",
    "df_cached, found = load_or_create_cache(\"congressional_trading\")\n",
    "if not found:\n",
    "    df_cached = client.congress_trading()\n",
    "    df_merged = save_with_history(df_cached, \"congressional_trading\")\n",
    "    print(f\"\\nüìä Total historique: {len(df_merged)} trades\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ DEUXI√àME EX√âCUTION (avec cache):\")\n",
    "df_cached2, found2 = load_or_create_cache(\"congressional_trading\")\n",
    "if found2:\n",
    "    print(f\"   Loaded: {len(df_cached2)} trades from cache\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ R√âSULTAT:\")\n",
    "print(\"\"\"\n",
    "Au lieu de:\n",
    "   - Fetch 1000 aujourd'hui\n",
    "   - Perte apr√®s 1 an (circular buffer)\n",
    "\n",
    "Maintenant:\n",
    "   - Fetch 1000 daily\n",
    "   - Accumule historique localement\n",
    "   - 1000 * 365 = 365,000 trades potentiels!\n",
    "   - Croissance progressive sans perte\n",
    "   \n",
    "Avantage: Apr√®s 1 an de collection, avoir ~365K trades\n",
    "         Puis utiliser /historical/{ticker} pour des tickers sp√©cifiques\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nüìÅ Cache saved at: {cache_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
