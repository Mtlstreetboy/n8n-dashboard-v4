services:
  finbert_api_gpu:
    build:
      context: ./services/finbert-api-gpu
    image: finbert-api-gpu:latest
    container_name: finbert_api_gpu
    ports:
      - "8089:8080"
    environment:
      - FINBERT_MODEL=ProsusAI/finbert
      - HF_HOME=/root/.cache/huggingface
    volumes:
      - ./local_files/hf_cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    # For non-swarm compose, recent versions also support:
    # gpus: all
