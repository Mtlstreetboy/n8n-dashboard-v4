# üìä AI Finance News Sentiment Analyzer - Guide Complet

## üéØ Objectif du Syst√®me

Analyser 30 nouvelles IA par jour sur les 100 derniers jours pour d√©tecter les bulles sp√©culatives via l'analyse de sentiment automatis√©e.

---

## üìê Architecture du Pipeline

Voir `ai-sentiment-pipeline.mmd` pour le diagramme visuel complet.

### Phases du Pipeline

1. **Collection** : Agr√©gation de sources multiples (NewsAPI, RSS, Reddit, HackerNews)
2. **Enrichissement** : D√©doublonnage, filtrage, extraction de contenu
3. **Analyse IA** : Scoring de sentiment par Ollama (-10 √† +10)
4. **Stockage** : CSV quotidiens + JSON historique
5. **Agr√©gation** : Moyennes mobiles (7j, 30j, 90j) + volatilit√©
6. **Visualisation** : Dashboard + alertes bulle

---

## üîß Scripts Python Cr√©√©s

### 1. `sentiment_analyzer.py`

**R√¥le :** Analyse le sentiment d'articles via Ollama.

**Input (stdin JSON):**
```json
{
  "articles": [
    {
      "title": "GPT-5 Release Announced",
      "content": "OpenAI announced...",
      "url": "https://...",
      "published_at": "2025-11-30T10:00:00Z"
    }
  ]
}
```

**Output (stdout JSON):**
```json
[
  {
    "title": "GPT-5 Release Announced",
    "url": "https://...",
    "published_at": "2025-11-30T10:00:00Z",
    "sentiment_score": 8,
    "justification": "Perc√©e majeure augmentant valuation march√©",
    "keywords": ["GPT-5", "OpenAI", "breakthrough"],
    "category": "product",
    "analyzed_at": "2025-11-30T16:30:00"
  }
]
```

**√âchelle de Scoring:**
- `-10` : Catastrophique (crash, scandale majeur)
- `-5` : Tr√®s n√©gatif (√©checs, r√©gulations s√©v√®res)
- `0` : Neutre (purement informatif)
- `+5` : Tr√®s positif (innovation, adoption)
- `+10` : R√©volutionnaire (perc√©e historique)

---

### 2. `aggregate_sentiment.py`

**R√¥le :** Agr√®ge les scores, calcule moyennes mobiles, d√©tecte les bulles.

**Input (stdin JSON):**
```json
{
  "articles": [
    {"title": "...", "sentiment_score": 8, "published_at": "2025-11-28", ...},
    {"title": "...", "sentiment_score": 6, "published_at": "2025-11-29", ...}
  ]
}
```

**Output (stdout JSON):**
```json
{
  "statistics": {
    "period_start": "2025-08-22",
    "period_end": "2025-11-30",
    "total_days": 100,
    "total_articles": 3000,
    "overall_avg_score": 5.2,
    "latest_ma_7d": 7.1,
    "latest_ma_30d": 6.3,
    "latest_ma_90d": 5.8,
    "latest_volatility_7d": 1.2,
    "bubble_risk_level": "HIGH",
    "bubble_indicators": [
      "EXTREME_OPTIMISM: Score quotidien > 7",
      "DIVERGENCE: MA7d d√©passe MA90d de 3.5 points"
    ]
  },
  "daily_data": [
    {"date": "2025-11-30", "daily_avg_score": 7.8, "ma_7d": 7.1, ...}
  ]
}
```

**Signaux de Bulle D√©tect√©s:**

1. **EXTREME_OPTIMISM** : Score quotidien > 7 (euphorie)
2. **DIVERGENCE** : MA 7j d√©passe MA 90j de plus de 3 points (d√©connexion tendance longue)
3. **COMPLACENCY** : Faible volatilit√© + optimisme √©lev√© (complaisance)
4. **SUSTAINED_RALLY** : Hausse continue sur 14+ jours (momentum insoutenable)

**Niveaux de Risque:**
- `LOW` : Aucun signal
- `MEDIUM` : 1-2 signaux
- `HIGH` : 3+ signaux ou EXTREME_OPTIMISM

---

## üóÇÔ∏è Structure de Donn√©es Recommand√©e

### Stockage Quotidien (CSV)
```
local_files/sentiment/
‚îú‚îÄ‚îÄ 2025-11-30_articles.csv
‚îú‚îÄ‚îÄ 2025-11-29_articles.csv
‚îî‚îÄ‚îÄ ...
```

**Colonnes CSV:**
- `title`, `url`, `published_at`, `source`
- `sentiment_score`, `justification`, `keywords`, `category`
- `analyzed_at`

### Stockage Historique (JSON)
```
local_files/sentiment_historical.json
```

Contient l'array complet de tous les articles pour faciliter l'agr√©gation.

---

## üîÑ Workflow n8n Recommand√©

### Workflow 1 : Collection + Analyse (Quotidien)

```
[Schedule Trigger - 8h00 chaque jour]
    ‚Üì
[HTTP Request - NewsAPI.org]
    ‚Üì
[HTTP Request - Google News RSS]
    ‚Üì
[Merge Data]
    ‚Üì
[Code Node - D√©duplication]
    ‚Üì
[Execute Command - sentiment_analyzer.py]
    ‚Üì
[Split In Batches - 10 articles] (√©viter timeout Ollama)
    ‚Üì
[Write Binary File - CSV quotidien]
    ‚Üì
[Read File - sentiment_historical.json]
    ‚Üì
[Code Node - Append nouveau data]
    ‚Üì
[Write Binary File - sentiment_historical.json]
```

### Workflow 2 : Agr√©gation + Alerte (Quotidien - apr√®s Workflow 1)

```
[Schedule Trigger - 20h00 chaque jour]
    ‚Üì
[Read File - sentiment_historical.json]
    ‚Üì
[Execute Command - aggregate_sentiment.py]
    ‚Üì
[IF Node - bubble_risk_level == "HIGH"]
    ‚Üì (TRUE)
[Send Email - Alerte Bulle D√©tect√©e]
    ‚Üì
[Write Binary File - daily_report.json]
```

---

## üåê Sources de Donn√©es Gratuites

### 1. NewsAPI.org
- **URL:** `https://newsapi.org/v2/everything?q=AI+OR+LLM+OR+GPT&language=en&sortBy=publishedAt`
- **Limite gratuite:** 100 requ√™tes/jour
- **Cl√© API:** Inscription requise

### 2. Google News RSS
- **URL:** `https://news.google.com/rss/search?q=artificial+intelligence+when:7d&hl=en-US&gl=US&ceid=US:en`
- **Limite:** Aucune (RSS public)

### 3. Reddit (via API)
- **Subreddits:** r/MachineLearning, r/artificial, r/OpenAI
- **Endpoint:** `https://www.reddit.com/r/MachineLearning/top.json?t=day`
- **Limite:** 60 requ√™tes/min sans auth

### 4. HackerNews API
- **URL:** `https://hacker-news.firebaseio.com/v0/topstories.json`
- **Puis:** `https://hacker-news.firebaseio.com/v0/item/{id}.json`
- **Limite:** Aucune

---

## üìä Exemple de R√©sultat d'Analyse

### Sc√©nario : Bulle D√©tect√©e

**Date:** 2025-11-30

**Statistiques:**
- Score moyen 100 jours : `5.2`
- Score moyen 7 derniers jours : `7.8`
- Volatilit√© 7j : `0.9` (tr√®s faible)
- Articles analys√©s : `3000`

**Signaux:**
- ‚ö†Ô∏è **EXTREME_OPTIMISM** : Score quotidien √† 8.1
- ‚ö†Ô∏è **DIVERGENCE** : MA 7j d√©passe MA 90j de 4.2 points
- ‚ö†Ô∏è **COMPLACENCY** : Volatilit√© < 1 avec optimisme > 7

**Verdict:** `BUBBLE RISK = HIGH`

**Interpr√©tation :** Le march√© IA est en phase d'euphorie. Les nouvelles sont syst√©matiquement interpr√©t√©es positivement, avec peu de remise en question. Historiquement, ce pattern pr√©c√®de des corrections de 20-40%.

---

## üõ†Ô∏è Installation des D√©pendances Python

Le script `aggregate_sentiment.py` n√©cessite **pandas**. Ajoutez-le au Dockerfile :

```dockerfile
# Dans votre Dockerfile actuel, ligne "RUN pip install..."
RUN pip install pandas requests numpy matplotlib
```

Puis rebuild :
```powershell
docker-compose down
docker-compose up -d --build
```

---

## üöÄ Prochaines √âtapes

1. **Tester le script d'analyse manuellement :**
   ```powershell
   echo '{"articles":[{"title":"Test","content":"AI breakthrough announced","url":"http://test.com","published_at":"2025-11-30"}]}' | docker exec -i n8n_data_architect python3 /data/scripts/sentiment_analyzer.py
   ```

2. **Cr√©er le workflow n8n de collection** (je peux g√©n√©rer le JSON si vous voulez)

3. **Configurer les API keys** dans n8n (NewsAPI, Reddit si besoin)

4. **Cr√©er un dashboard avec `matplotlib`** pour visualiser les graphiques (script Python additionnel)

---

## üìà M√©triques de Performance

- **Temps d'analyse par article :** ~3-5 secondes (Ollama local)
- **Throughput quotidien :** 30 articles = ~2-3 minutes
- **Stockage :** ~10 MB pour 100 jours de donn√©es

---

## üîí Notes de S√©curit√©

- Les API keys doivent √™tre dans des **variables d'environnement** n8n (jamais hardcod√©es)
- Le fichier `sentiment_historical.json` peut devenir volumineux ‚Üí impl√©menter une rotation mensuelle
- Ollama tourne en local ‚Üí aucune donn√©e sensible envoy√©e √† des tiers

---

**Pr√™t √† impl√©menter ?** Dites-moi si vous voulez que je g√©n√®re :
1. Le workflow n8n complet (JSON √† importer)
2. Un script de visualisation avec graphiques
3. Un script de test unitaire pour valider le pipeline
